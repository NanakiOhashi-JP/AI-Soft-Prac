{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc44d038-8038-47d6-8fc1-8975c429be93",
   "metadata": {},
   "source": [
    "# 人工知能とソフトコンピューティング 第8回 CNN 演習\n",
    "## 追加資料\n",
    "* MNISTの手書き文字分類タスクに対してエポック数を増やして訓練した結果\n",
    "* 同じタスクを1層の全結合ニューラルネットワークで分類した結果"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef25cd28",
   "metadata": {},
   "source": [
    "## Google Collaboratory 利用の準備\n",
    "\n",
    "以下の準備をする\n",
    "* pytorch lightningを環境にインストールする\n",
    "* Google Driveにアクセスできるようにする"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dabb0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b80f95f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7243219c-8597-4ee3-99ff-d2d53fc14979",
   "metadata": {},
   "source": [
    "### 準備"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae454de",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = '/content/drive/MyDrive/Colab Notebooks'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c31cc6f0-c5d1-4a14-b6a0-6111dc2896f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path # ファイルパスの取り扱い\n",
    "import matplotlib.pyplot as plt # グラフ描画\n",
    "import numpy as np # 数値取扱い\n",
    "import pandas as pd # データ解析\n",
    "from sklearn.model_selection import train_test_split # 訓練データとテストデータの分割\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
    "import pytorch_lightning as L\n",
    "from pytorch_lightning.utilities.model_summary import ModelSummary\n",
    "from torchmetrics import Accuracy\n",
    "from torchvision import transforms # 画像変換ライブラリ\n",
    "from torchvision.datasets import MNIST # MNISTのデータ\n",
    "\n",
    "#訓練データ\n",
    "train_dataset = MNIST(root=Path(base_path, 'data'),\n",
    "                      train=True,\n",
    "                      transform=transforms.ToTensor(),\n",
    "                      download = True)\n",
    "#検証データ\n",
    "test_dataset = MNIST(root=Path(base_path, 'data'),\n",
    "                      train=False,\n",
    "                      transform=transforms.ToTensor(),\n",
    "                      download = True)\n",
    "\n",
    "# 60000枚の学習用ベースデータを 48000枚（訓練用データ）と12000枚（訓練中の評価用データ）に分割\n",
    "# 乱数シードを固定して毎回同じ分割になるようにする\n",
    "generator = torch.Generator().manual_seed(0)\n",
    "train_dataset, val_dataset = random_split(train_dataset, [0.8, 0.2], generator=generator)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da4516ad-0093-4cc6-9743-2d2dabe0d1d3",
   "metadata": {},
   "source": [
    "### ニューラルネットワークの定義とコンパイル\n",
    "* model_cnn は演習で用いた資料と同じもの\n",
    "* model_fcn は全結合ネットワーク1層のみ（単純パーセプトロン）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b2afff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNNの定義（同じもの）\n",
    "class MNISTCNN(L.LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters() # ハイパーパラメータを保存\n",
    "        self.example_input_array = torch.zeros((1, 1, 28, 28)) # 枚数×色チャネル数×横ピクセル数×縦ピクセル数\n",
    "\n",
    "        # 出力クラス数（数字 0～9 の10クラス分類）\n",
    "        self.num_classes = 10 \n",
    "        # CNNモデル定義\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3, stride=1, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2, padding=0),\n",
    "\n",
    "            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2, padding=0),\n",
    "\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2, padding=0),\n",
    "            nn.Flatten(), # Flatten層\n",
    "            nn.Linear(in_features=64, out_features=self.num_classes), # 全結合層\n",
    "        )\n",
    "\n",
    "        # 損失関数: クロスエントロピー損失関数（多クラス分類用）\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        \n",
    "        # 評価指標: Kerasのmetrics=['accuracy'] に対応\n",
    "        self.train_acc = Accuracy(task=\"multiclass\", num_classes=self.num_classes)\n",
    "        self.val_acc = Accuracy(task=\"multiclass\", num_classes=self.num_classes)\n",
    "        self.test_acc = Accuracy(task=\"multiclass\", num_classes=self.num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        # オプティマイザ: Adam (デフォルトの学習率 0.001)\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=0.001) # デフォルトの学習率を設定\n",
    "        return optimizer\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = self.criterion(logits, y)\n",
    "\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        self.train_acc(preds, y)\n",
    "        \n",
    "        self.log('train_loss', loss, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        self.log('train_accuracy', self.train_acc, on_step=False, on_epoch=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = self.criterion(logits, y)\n",
    "\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        self.val_acc(preds, y)\n",
    "        \n",
    "        self.log('val_loss', loss, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        self.log('val_accuracy', self.val_acc, on_step=False, on_epoch=True)\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = self.criterion(logits, y)\n",
    "\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        self.test_acc(preds, y)\n",
    "        \n",
    "        self.log('test_loss', loss, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        self.log('test_accuracy', self.test_acc, on_step=False, on_epoch=True)\n",
    "\n",
    "model_cnn = MNISTCNN()\n",
    "print(ModelSummary(model_cnn, max_depth=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b4f8e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTFCN(L.LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.num_classes = 10\n",
    "        self.input_size = 28\n",
    "        self.example_input_array = torch.zeros((1, 1, self.input_size, self.input_size))\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Flatten(), # Flatten層: 1次元データへの変換\n",
    "            nn.Linear(in_features=self.input_size*self.input_size, out_features=self.num_classes)\n",
    "        )\n",
    "\n",
    "        # 損失関数: クロスエントロピー損失関数（多クラス分類用）\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        \n",
    "        # 評価指標: 訓練・検証・テストでの精度計算用\n",
    "        self.train_acc = Accuracy(task=\"multiclass\", num_classes=self.num_classes)\n",
    "        self.val_acc = Accuracy(task=\"multiclass\", num_classes=self.num_classes)\n",
    "        self.test_acc = Accuracy(task=\"multiclass\", num_classes=self.num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        # オプティマイザ: Adam (デフォルトの学習率 0.001)\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=0.001) # デフォルトの学習率を設定\n",
    "        return optimizer\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = self.criterion(logits, y)\n",
    "\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        self.train_acc(preds, y)\n",
    "        \n",
    "        self.log('train_loss', loss, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        self.log('train_accuracy', self.train_acc, on_step=False, on_epoch=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = self.criterion(logits, y)\n",
    "\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        self.val_acc(preds, y)\n",
    "        \n",
    "        self.log('val_loss', loss, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        self.log('val_accuracy', self.val_acc, on_step=False, on_epoch=True)\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = self.criterion(logits, y)\n",
    "\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        self.test_acc(preds, y)\n",
    "        \n",
    "        self.log('test_loss', loss, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        self.log('test_accuracy', self.test_acc, on_step=False, on_epoch=True)\n",
    "\n",
    "model_fcn = MNISTFCN()\n",
    "print(ModelSummary(model_fcn, max_depth=-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf68202-40c2-4965-9d5e-a0300efbd5bd",
   "metadata": {},
   "source": [
    "### 定義した二つのネットワークの訓練\n",
    "* エポック数100で訓練（時間がかかる可能性があるので実行する場合は適切に調整）\n",
    "* バッチサイズや投入するデータは演習と同じ\n",
    "* 訓練履歴はそれぞれの変数に格納"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15cd4c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10 # エポック数\n",
    "batch_size = 32 # バッチサイズ\n",
    "\n",
    "# 1. データローダーとモデルのインスタンス化\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_dataloader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# 訓練履歴を保存するフォルダ\n",
    "log_folder = Path(base_path, \"logs\")\n",
    "\n",
    "# CNNモデルの学習\n",
    "checkpoint_callback_cnn = L.callbacks.ModelCheckpoint(\n",
    "    save_last=True,\n",
    ")\n",
    "cnn_logger = L.loggers.CSVLogger(log_folder, name='cnn2')\n",
    "cnn_trainer = L.Trainer(\n",
    "    max_epochs=epochs,\n",
    "    logger=cnn_logger,\n",
    "    callbacks=[checkpoint_callback_cnn],\n",
    "    deterministic=True,\n",
    "    enable_progress_bar=True\n",
    ")\n",
    "cnn_trainer.fit(model_cnn, train_dataloaders=train_dataloader, val_dataloaders=val_dataloader)\n",
    "\n",
    "# FCNモデルの学習\n",
    "checkpoint_callback_fcn = L.callbacks.ModelCheckpoint(\n",
    "    save_last=True,\n",
    ")\n",
    "fcn_logger = L.loggers.CSVLogger(log_folder, name='fcn2')\n",
    "fcn_trainer = L.Trainer(\n",
    "    max_epochs=epochs,\n",
    "    logger=fcn_logger,\n",
    "    callbacks=[checkpoint_callback_fcn],\n",
    "    deterministic=True,\n",
    "    enable_progress_bar=True\n",
    ")\n",
    "fcn_trainer.fit(model_fcn, train_dataloaders=train_dataloader, val_dataloaders=val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "938eb90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_history(log_path):\n",
    "    log_file = Path(log_path, \"metrics.csv\")\n",
    "    history = pd.read_csv(log_file)\n",
    "    train_history = history.dropna(subset=['train_loss']).reset_index(drop=True) \n",
    "    val_history = history.dropna(subset=['val_loss']).reset_index(drop=True)\n",
    "    return train_history, val_history\n",
    "\n",
    "def show_accuracy_and_loss_graphs(train_history, val_history, epochs, epoch_from = 1): # 訓練履歴（精度・損失）を描画する関数\n",
    "    training_accuracies = train_history[\"train_accuracy\"] # 訓練用データに対する精度\n",
    "    validation_accuracies = val_history[\"val_accuracy\"] # 評価用データに対する精度\n",
    "    training_losses = train_history[\"train_loss\"] # 訓練用データに対する損失\n",
    "    validation_losses = val_history[\"val_loss\"] # 評価用データに対する損失\n",
    "    \n",
    "    epochs_range = range(epoch_from, epochs + 1) # 1 から epochs までの描画範囲を指定\n",
    "    figure = plt.figure(figsize = (10, 5))\n",
    "    subplot = plt.subplot(1, 2, 1)\n",
    "    subplot.plot(epochs_range, training_accuracies, label = \"Training Accuracy\") # 訓練用データに対する精度のグラフ描画\n",
    "    subplot.plot(epochs_range, validation_accuracies, label = \"Validation Accuracy\") # 評価用データに対する精度のグラフ描画\n",
    "    subplot.set_xlabel(\"epochs\")\n",
    "    subplot.legend()\n",
    "    plt.title(\"Training and Validation Accuracy\")\n",
    "    subplot = plt.subplot(1, 2, 2)\n",
    "    subplot.plot(epochs_range, training_losses, label = \"Training Loss\") # 訓練用データに対する損失のグラフ描画\n",
    "    subplot.plot(epochs_range, validation_losses, label = \"Validation Loss\") # 評価用データに対する損失のグラフ描画\n",
    "    subplot.set_xlabel(\"epochs\")\n",
    "    subplot.legend()\n",
    "    plt.title(\"Training and Validation Loss\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38cb9acc-ef5a-42c4-9bf7-12dff35cf0ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\")\n",
    "print(\"CNN エポック数{}の訓練履歴\".format(epochs))\n",
    "cnn_log_path = Path(log_folder, \"cnn2\", f\"version_{cnn_trainer.logger.version}\")\n",
    "cnn_train_history, cnn_val_history = load_history(cnn_log_path)\n",
    "show_accuracy_and_loss_graphs(cnn_train_history, cnn_val_history, epochs)\n",
    "\n",
    "print(\"\")\n",
    "print(\"FCN エポック数{}の訓練履歴\".format(epochs))\n",
    "fcn_log_path = Path(log_folder, \"fcn2\", f\"version_{fcn_trainer.logger.version}\")\n",
    "fcn_train_history, fcn_val_history = load_history(fcn_log_path)\n",
    "show_accuracy_and_loss_graphs(fcn_train_history, fcn_val_history, epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf8c919-1b67-4a24-acd4-d24dd934720b",
   "metadata": {},
   "source": [
    "### 二つのモデルにテストデータを与えて評価・分類"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43325b6e-1bbe-49c4-a25a-c953f04808f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataloader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=len(test_dataset)\n",
    ")\n",
    "score_cnn = cnn_trainer.test(model_cnn, dataloaders=test_dataloader, verbose=False)[0] # CNN評価\n",
    "score_fcn = fcn_trainer.test(model_fcn, dataloaders=test_dataloader, verbose=False)[0] # FCN評価\n",
    "\n",
    "print(\"CNN {}エポック 精度 =\".format(epochs), score_cnn['test_accuracy'])\n",
    "print(\"CNN {}エポック 損失 =\".format(epochs), score_cnn['test_loss'])\n",
    "print(\"FCN {}エポック 精度 =\".format(epochs), score_fcn['test_accuracy'])\n",
    "print(\"FCN {}エポック 損失 =\".format(epochs), score_fcn['test_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c146657-7041-4944-9f38-0d8ba585c010",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images, test_labels = next(iter(test_dataloader)) # 画像とラベルをTensorで取得\n",
    "\n",
    "predict_data_loader = DataLoader(\n",
    "    test_images,\n",
    "    batch_size=len(test_images)\n",
    ")\n",
    "\n",
    "def predict(trainer, data_loader):\n",
    "    probs = trainer.predict(dataloaders=data_loader)\n",
    "    predictions = torch.cat(probs, dim=0) # リストprobの要素を結合して1つのTensorにする\n",
    "    predictions = nn.functional.softmax(predictions, dim=1) # 各クラスの予測値の合計が1になるようにする（確率に変換）\n",
    "    return predictions\n",
    "\n",
    "predictions_cnn = predict(cnn_trainer, predict_data_loader) # CNN分類\n",
    "predictions_fcn = predict(fcn_trainer, predict_data_loader) # FCN分類"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8114856c-4aac-4b02-aae6-90fcd344b112",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_prediction_result(image, correct, result):\n",
    "    figure = plt.figure(figsize = [6.4, 2.4])\n",
    "    subplot = plt.subplot(1, 2, 1)\n",
    "    plt.imshow(image, cmap = plt.cm.binary)\n",
    "    plt.title(\"correct label = {}\".format(correct))\n",
    "    plt.axis(\"off\")\n",
    "    subplot = plt.subplot(1, 2, 2)\n",
    "    plt.bar(range(len(result)), result)\n",
    "    plt.xticks(range(len(result)), range(len(result)))\n",
    "    plt.ylim(0, 1)\n",
    "    plt.title(\"probabilites\")\n",
    "    plt.show()\n",
    "\n",
    "num_examples = 5\n",
    "count = 0\n",
    "print(\"\")\n",
    "print(\"CNNで正しく分類された画像の例\") \n",
    "for i in range(len(predictions_cnn)):\n",
    "    if (np.argmax(predictions_cnn[i]) == test_labels[i]):\n",
    "        show_prediction_result(test_images[i].squeeze(), test_labels[i], predictions_cnn[i])\n",
    "        count += 1\n",
    "        if (count > num_examples):\n",
    "            break\n",
    "print(\"\")\n",
    "print(\"CNNで誤って分類された画像の例\")\n",
    "count = 0\n",
    "for i in range(len(predictions_cnn)):\n",
    "    if (np.argmax(predictions_cnn[i]) != test_labels[i]):\n",
    "        show_prediction_result(test_images[i].squeeze(), test_labels[i], predictions_cnn[i])\n",
    "        count += 1\n",
    "        if (count > num_examples):\n",
    "            break\n",
    "count = 0\n",
    "print(\"\")\n",
    "print(\"FCNで正しく分類された画像の例\") \n",
    "for i in range(len(predictions_fcn)):\n",
    "    if (np.argmax(predictions_fcn[i]) == test_labels[i]):\n",
    "        show_prediction_result(test_images[i].squeeze(), test_labels[i], predictions_fcn[i])\n",
    "        count += 1\n",
    "        if (count > num_examples):\n",
    "            break\n",
    "print(\"\")\n",
    "print(\"FCNで誤って分類された画像の例\")\n",
    "count = 0\n",
    "for i in range(len(predictions_fcn)):\n",
    "    if (np.argmax(predictions_fcn[i]) != test_labels[i]):\n",
    "        show_prediction_result(test_images[i].squeeze(), test_labels[i], predictions_fcn[i])\n",
    "        count += 1\n",
    "        if (count > num_examples):\n",
    "            break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
