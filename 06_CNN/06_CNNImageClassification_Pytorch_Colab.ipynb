{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc44d038-8038-47d6-8fc1-8975c429be93",
   "metadata": {},
   "source": [
    "# 人工知能とソフトコンピューティング 第6回 CNN 演習\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e41fce6",
   "metadata": {},
   "source": [
    "## Google Collaboratory 利用の準備\n",
    "\n",
    "以下の準備をする\n",
    "* pytorch lightningを環境にインストールする\n",
    "* Google Driveにアクセスできるようにする"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43df0040",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc330db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb15eb47",
   "metadata": {},
   "source": [
    "## 分析対象となるデータの準備\n",
    "ここではMNISTの手書き数字画像分類を行う"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a7b41ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = '/content/drive/MyDrive/Colab Notebooks'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87fa8e26-e3bd-4a59-8d58-d418820daa7b",
   "metadata": {},
   "source": [
    "### ステップ1\n",
    "必要なライブラリをインポートする  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6f225d-abce-4f45-abb7-4ac95b4f87df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path # ファイルパスの取り扱い\n",
    "import matplotlib.pyplot as plt # グラフ描画\n",
    "import numpy as np # 数値取扱い\n",
    "import pandas as pd # ファイル読み込み，データフレーム\n",
    "from sklearn.model_selection import train_test_split # 訓練データとテストデータの分割\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
    "import pytorch_lightning as L\n",
    "from pytorch_lightning.utilities.model_summary import ModelSummary\n",
    "from torchmetrics import Accuracy\n",
    "from torchvision import transforms # 画像変換ライブラリ\n",
    "from torchvision.datasets import MNIST # MNISTのデータ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23af63f3-6f53-4d39-8ac8-9cfca1af54a3",
   "metadata": {},
   "source": [
    "### ステップ2\n",
    "MNISTデータセット（手書きの数字と正解ラベルのセット）を分類の対象とし，訓練データとテストデータに分割  \n",
    "※ 訓練データの一部は，訓練中の評価データとして用いる\n",
    "* train_images, train_labels: ニューラルネットワークを訓練するのに必要な訓練データ（画像と正解ラベル）\n",
    "* validation_images, validation_labels: ニューラルネットワークの訓練中に用いる評価データ（画像と正解ラベル）\n",
    "* test_images, test_labels: 学習済みのニューラルネットワークに対するテストデータ（画像と正解ラベル）\n",
    "  \n",
    "データを読み込む際に，transforms.ToTensor() を使って画像の白黒の濃淡を0～1の範囲に正規化している"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac274ac-8fb1-4be3-a632-60b58be5a1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#訓練データ\n",
    "train_dataset = MNIST(root=Path(base_path, 'data'),\n",
    "                      train=True,\n",
    "                      transform=transforms.ToTensor(),\n",
    "                      download = True)\n",
    "#検証データ\n",
    "test_dataset = MNIST(root=Path(base_path, 'data'),\n",
    "                      train=False,\n",
    "                      transform=transforms.ToTensor(),\n",
    "                      download = True)\n",
    "\n",
    "# 60000枚の学習用ベースデータを 48000枚（訓練用データ）と12000枚（訓練中の評価用データ）に分割\n",
    "# 乱数シードを固定して毎回同じ分割になるようにする\n",
    "generator = torch.Generator().manual_seed(0)\n",
    "train_dataset, val_dataset = random_split(train_dataset, [0.8, 0.2], generator=generator)\n",
    "\n",
    "# 個々の画像データの形状は、枚数x色チャネル数×横ピクセル数×縦ピクセル数\n",
    "# 色チャネルは1次元（白黒の濃淡 0～255），RGBデータの場合は3次元を用いる\n",
    "# 画像の大きさは 28×28\n",
    "# 白黒の濃淡は0～1の範囲に正規化されている"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe7c514-e7ac-49ec-98a7-f0c5dc08fd6c",
   "metadata": {},
   "source": [
    "### ステップ3\n",
    "データ中の画像と正解ラベルをいくつか表示して確認する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd519dc6-576a-4905-a5bf-393bf0296480",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (5, 5)) # 図オブジェクト生成（サイズ 5インチ×5インチ）\n",
    "\n",
    "for i in range(9):\n",
    "    image, label = train_dataset[i]\n",
    "    subplot = plt.subplot(3, 3, i + 1) # 図の中に3×3の区画を作り，その i+1番目の区画を指定\n",
    "    # squeezeは[1, x, y] のTensorを[x,y]のTensorに変換する\n",
    "    plt.imshow(image.squeeze(), cmap = plt.cm.binary) # 画像を白黒で表示\n",
    "    plt.title(label) # タイトルはデータが持つ正解ラベルとする\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da4516ad-0093-4cc6-9743-2d2dabe0d1d3",
   "metadata": {},
   "source": [
    "## ニューラルネットワーク（CNN）の構造定義"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e42d6a3-782a-49d7-b405-846ec28ca6c1",
   "metadata": {},
   "source": [
    "### ステップ4\n",
    "次の構造を持つニューラルネットワークのアーキテクチャ（Sequential：逐次構造）を定義\n",
    "* Conv2D: 2次元畳み込み層\n",
    "* MaxPooling2D: 2次元最大プーリング層\n",
    "* Conv2D: 2次元畳み込み層\n",
    "* MaxPooling2D: 2次元最大プーリング層\n",
    "* Conv2D: 2次元畳み込み層\n",
    "* Flatten: 1次元へのデータ変換層\n",
    "* Dense: 全結合層\n",
    "\n",
    "次の訓練方法を設定\n",
    "* 重み計算の最適化アルゴリズム Adam（Adaptive Moment Estimation）\n",
    "* 損失関数（モデルと期待との差異を評価する尺度）CrossEntropyLoss（クロスエントロピー損失）\n",
    "* 訓練中に訓練データと評価データに対して取得する値 accuracy （分類精度）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ddfdca-518a-4a24-b27d-cac63f1ed552",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTCNN(L.LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters() # ハイパーパラメータを保存\n",
    "        self.example_input_array = torch.zeros((1, 1, 28, 28)) # 枚数×色チャネル数×横ピクセル数×縦ピクセル数\n",
    "\n",
    "        # 出力クラス数（数字 0～9 の10クラス分類）\n",
    "        self.num_classes = 10 \n",
    "        # CNNモデル定義\n",
    "        self.model = nn.Sequential(\n",
    "            # Conv2d: 2次元の畳み込み層 フィルタ（出力）数 16，フィルタサイズ 3x3，ストライド 1x1，パディング なし\n",
    "            #         1x28x28 のデータを入力し，3x3 のフィルタを 1x1 ずつスライドさせる\n",
    "            #         3x3 のフィルタを 16枚用意して同じデータに適用する\n",
    "            #         結果として，16x26x26 のデータを出力\n",
    "            nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3, stride=1, padding=0),\n",
    "            nn.ReLU(), # 活性化関数 ReLU\n",
    "            #\n",
    "            # MaxPool2d: 2次元の最大プーリング層　プールサイズ 2x2，ストライド 2x2，パディング なし\n",
    "            #               前段の Conv2d層から 16x26x26 のデータを入力\n",
    "            #               26x26 の行列を 2x2 の部分 13x13 個に分割，1つの部分に含まれる 4つの数のうち最大値を出力\n",
    "            #               結果として，16x13x13 のデータを出力\n",
    "            #               MaxPooling2d の代わりに AvgPool2d を用いると平均プーリング層を定義できる\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2, padding=0),\n",
    "            #\n",
    "            # Conv2D: 2次元の畳み込み層 フィルタ数 32，フィルタサイズ 3x3，ストライド 1x1，パディング なし\n",
    "            #         前段の MaxPool2d層から 16x13x13 のデータを入力，3x3 のフィルタをスライド\n",
    "            #         3x3のフィルタを 32枚用意して，32x11x11 のデータを出力\n",
    "            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=0),\n",
    "            nn.ReLU(), # 活性化関数 ReLU\n",
    "            #\n",
    "            # MaxPooling2D: 2次元の最大プーリング層\n",
    "            #               前段の Conv2d層から 32x11x11 のデータを入力，2x2の最大値を取る\n",
    "            #               結果として 32x5x5 のデータを出力\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2, padding=0), # MaxPooling層\n",
    "            #\n",
    "            # Conv2D: 2次元の畳み込み層 フィルタ数 64，フィルタサイズ 3x3，ストライド 1x1，パディング なし\n",
    "            #         前段の MaxPooling2D層から 32x5x5 のデータを入力，3x3 のフィルタをスライド\n",
    "            #         3x3のフィルタを 64枚用意して，64x3x3 のデータを出力\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=0),\n",
    "            nn.ReLU(), # 活性化関数 ReLU\n",
    "            #\n",
    "            # MaxPooling2D: 2次元の最大プーリング層\n",
    "            #               前段の Conv2D層から 64x3x3 のデータを入力，2x2の最大値を取る（終端の余りデータは無視）\n",
    "            #               結果として 64x1x1 のデータを出力\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2, padding=0), # MaxPooling層\n",
    "            #\n",
    "            # Flatten: 1次元データへの変換層\n",
    "            #          前段の MaxPooling層から 64x1x1 のデータを入力\n",
    "            #          64個の値のリストを出力\n",
    "            nn.Flatten(), # Flatten層\n",
    "            #\n",
    "            # Linear: 全結合のニューロン層 ユニット（出力）数 10，活性化関数 Softmax\n",
    "            #        前段の Flatten層から64個の値リストを入力\n",
    "            #        num_classes 個のユニットから値を出力\n",
    "            nn.Linear(in_features=64, out_features=self.num_classes), # 全結合層\n",
    "        )\n",
    "\n",
    "        # 損失関数: クロスエントロピー損失関数（多クラス分類用）\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        \n",
    "        # 評価指標: Kerasのmetrics=['accuracy'] に対応\n",
    "        self.train_acc = Accuracy(task=\"multiclass\", num_classes=self.num_classes)\n",
    "        self.val_acc = Accuracy(task=\"multiclass\", num_classes=self.num_classes)\n",
    "        self.test_acc = Accuracy(task=\"multiclass\", num_classes=self.num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 順伝播でモデルの出力を計算\n",
    "        return self.model(x)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        # オプティマイザ: Adam (デフォルトの学習率 0.001)\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=0.001) # デフォルトの学習率を設定\n",
    "        return optimizer\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        # 訓練データのバッチを使って損失を計算\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = self.criterion(logits, y)\n",
    "\n",
    "        # 損失と精度を記録\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        self.train_acc(preds, y)\n",
    "        \n",
    "        # on_epoch=True でエポック終了時に平均値を記録\n",
    "        self.log('train_loss', loss, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        self.log('train_accuracy', self.train_acc, on_step=False, on_epoch=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        # 検証データのバッチを使って損失を計算(training_stepと同様だが戻り値は不要)\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = self.criterion(logits, y)\n",
    "\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        self.val_acc(preds, y)\n",
    "        \n",
    "        self.log('val_loss', loss, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        self.log('val_accuracy', self.val_acc, on_step=False, on_epoch=True)\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        # テストデータのバッチを使って損失を計算(training_stepと同様だが戻り値は不要)\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = self.criterion(logits, y)\n",
    "\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        self.test_acc(preds, y)\n",
    "        \n",
    "        self.log('test_loss', loss, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        self.log('test_accuracy', self.test_acc, on_step=False, on_epoch=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83f04982-80f4-4634-9b0b-9e49f213fa9a",
   "metadata": {},
   "source": [
    "### ステップ5\n",
    "定義したアーキテクチャの概要を確認  \n",
    "モデル定義の行（model）およびモデルの要素(model.X)を見て、入出力関係（大きさ，次元数）に設計との不一致や層間の不整合がないかを確認する\n",
    "* Type: レイヤの種類\n",
    "* Params: 学習により決定するパラメータ（重み）の数\n",
    "* In sizes: 入力データの形式\n",
    "* Out sizes: 出力データの形式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbad7da4-f5fc-4058-b57e-5a8de16e3e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "ModelSummary(MNISTCNN(), max_depth=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf68202-40c2-4965-9d5e-a0300efbd5bd",
   "metadata": {},
   "source": [
    "## CNNの訓練"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f51e312-e17a-41b9-ae66-6bdc0a45c647",
   "metadata": {},
   "source": [
    "### ステップ6\n",
    "モデルに訓練データを投入し，ネットワークの「重み」を計算\n",
    "* 訓練データ（画像と正解ラベル）\n",
    "* エポック数：10\n",
    "* バッチサイズ：32\n",
    "* 訓練結果の評価データ（画像と正解ラベル）\n",
    "* 訓練の履歴を記録\n",
    "\n",
    "バッチサイズで訓練データを分割し，すべての訓練データに対して繰り返しパラメータを最適化するまでの処理が1エポック  \n",
    "訓練データの数 / バッチサイズ で 1エポックでの繰り返し数が決まる  \n",
    "この例の場合，訓練データ数 48000枚でバッチサイズ 32 なので，1エポックにつき1500回の重み計算の繰り返しが行われる，それをエポック数（10）回繰り返す  \n",
    "バッチサイズとエポック数はモデルの性能に影響を与える"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e27143-7aed-4c2a-a871-6969e032ca24",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10 # エポック数\n",
    "batch_size = 32 # バッチサイズ\n",
    "\n",
    "# 1. データローダーとモデルのインスタンス化\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_dataloader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "mnist_cnn = MNISTCNN()\n",
    "\n",
    "# 訓練履歴を保存するフォルダ\n",
    "log_folder = Path(base_path, \"logs\")\n",
    "\n",
    "# CNNモデルの学習\n",
    "checkpoint_callback_cnn = L.callbacks.ModelCheckpoint(\n",
    "    save_last=True,\n",
    ")\n",
    "cnn_logger = L.loggers.CSVLogger(log_folder, name='cnn')\n",
    "cnn_trainer = L.Trainer(\n",
    "    max_epochs=epochs,\n",
    "    logger=cnn_logger,\n",
    "    callbacks=[checkpoint_callback_cnn],\n",
    "    deterministic=True,\n",
    "    enable_progress_bar=True\n",
    ")\n",
    "cnn_trainer.fit(mnist_cnn, train_dataloaders=train_dataloader, val_dataloaders=val_dataloader)\n",
    "checkpoint_path = checkpoint_callback_cnn.last_model_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "331fe334-718e-4585-9880-67827e82e706",
   "metadata": {},
   "source": [
    "### ステップ7\n",
    "訓練履歴（精度，損失）の確認\n",
    "* 訓練用データに対する分類の精度と評価用データに対する分類の精度\n",
    "* 訓練用データに対する損失と評価用データに対する損失\n",
    "\n",
    "これらのエポック毎の記録が lightning_logs フォルダに保存されているので，読み込んでグラフに描画することで，学習が進むにつれてどのように変化したかを把握することができる "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "606a358c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_history(log_path):\n",
    "    log_file = Path(log_path, \"metrics.csv\")\n",
    "    history = pd.read_csv(log_file)\n",
    "    train_history = history.dropna(subset=['train_loss']).reset_index(drop=True) \n",
    "    val_history = history.dropna(subset=['val_loss']).reset_index(drop=True)\n",
    "    return train_history, val_history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b9783bb",
   "metadata": {},
   "source": [
    "記録から学習が進むにつれてどのように変化したかをグラフに描画して把握するための関数を定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38cb9acc-ef5a-42c4-9bf7-12dff35cf0ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_accuracy_and_loss_graphs(train_history, val_history, epochs, epoch_from = 1): # 訓練履歴（精度・損失）を描画する関数\n",
    "    training_accuracies = train_history[\"train_accuracy\"] # 訓練用データに対する精度\n",
    "    validation_accuracies = val_history[\"val_accuracy\"] # 評価用データに対する精度\n",
    "    training_losses = train_history[\"train_loss\"] # 訓練用データに対する損失\n",
    "    validation_losses = val_history[\"val_loss\"] # 評価用データに対する損失\n",
    "    \n",
    "    epochs_range = range(epoch_from, epochs + 1) # 1 から epochs までの描画範囲を指定\n",
    "    figure = plt.figure(figsize = (10, 5))\n",
    "    subplot = plt.subplot(1, 2, 1)\n",
    "    subplot.plot(epochs_range, training_accuracies, label = \"Training Accuracy\") # 訓練用データに対する精度のグラフ描画\n",
    "    subplot.plot(epochs_range, validation_accuracies, label = \"Validation Accuracy\") # 評価用データに対する精度のグラフ描画\n",
    "    subplot.set_xlabel(\"epochs\")\n",
    "    subplot.legend()\n",
    "    plt.title(\"Training and Validation Accuracy\")\n",
    "    subplot = plt.subplot(1, 2, 2)\n",
    "    subplot.plot(epochs_range, training_losses, label = \"Training Loss\") # 訓練用データに対する損失のグラフ描画\n",
    "    subplot.plot(epochs_range, validation_losses, label = \"Validation Loss\") # 評価用データに対する損失のグラフ描画\n",
    "    subplot.set_xlabel(\"epochs\")\n",
    "    subplot.legend()\n",
    "    plt.title(\"Training and Validation Loss\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae99aab8-8284-49bd-8881-881d8c521ec9",
   "metadata": {},
   "source": [
    "### ステップ8\n",
    "履歴の表示（ステップ7で定義した関数を使用）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8baf0d58-0996-4685-a934-9326cd40b86d",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_path = Path(log_folder, \"cnn\", f\"version_{cnn_trainer.logger.version}\")\n",
    "cnn_train_history, cnn_val_history = load_history(log_path)\n",
    "show_accuracy_and_loss_graphs(cnn_train_history, cnn_val_history, epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86490ae2-f422-4e46-97e3-e155ddae71e5",
   "metadata": {},
   "source": [
    "## 訓練済みのCNNの読み込み"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b38a2081-fdb9-4511-83f5-f5731051fc74",
   "metadata": {},
   "source": [
    "### ステップ9\n",
    "モデルの追加訓練\n",
    "* 復元されたモデルをさらに（保存された時点から）訓練する\n",
    "* 追加訓練済みのモデルは（必要に応じて）保存しても良い"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e1933e-30c1-4f03-981a-c3956b26ffc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_restored = 5\n",
    "batch_size_restored = 32\n",
    "\n",
    "# 1. データとモデルのインスタンス化\n",
    "\n",
    "train_dataloader_restored = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size_restored,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_dataloader_restored = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=batch_size_restored,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "\n",
    "# 2. 訓練履歴を記録するロガーと訓練方法の設定\n",
    "# 保存前のモデルと同じログフォルダを指定すると，新しいバージョンで訓練履歴が追加されて保存されます\n",
    "checkpoint_restored_callback_cnn = L.callbacks.ModelCheckpoint(\n",
    "    save_last=True,\n",
    ")\n",
    "cnn_restored_logger = L.loggers.CSVLogger(log_folder, name='cnn')\n",
    "cnn_trainer_restored = L.Trainer(\n",
    "    max_epochs=epochs_restored,\n",
    "    logger=cnn_restored_logger,\n",
    "    callbacks=[checkpoint_restored_callback_cnn],\n",
    "    enable_progress_bar=True\n",
    ")\n",
    "\n",
    "# 3. 訓練開始\n",
    "\n",
    "# 追加訓練するモデルを読み込む\n",
    "restored_model = MNISTCNN.load_from_checkpoint(checkpoint_path=checkpoint_path)\n",
    "\n",
    "cnn_trainer_restored.fit(restored_model, \n",
    "                         train_dataloaders=train_dataloader_restored,\n",
    "                         val_dataloaders=val_dataloader_restored)\n",
    "checkpoint_path = checkpoint_restored_callback_cnn.last_model_path\n",
    "# 追加学習履歴を表示したい場合はこの下の行を実行する\n",
    "#log_path = Path(log_folder, \"cnn\", f\"version_{cnn_trainer_restored.logger.version}\")\n",
    "#cnn_restored_train_history, cnn_restored_val_history = load_history(log_path)\n",
    "#show_accuracy_and_loss_graphs(cnn_restored_train_history, cnn_restored_val_history, epochs_restored)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b3442fe-d5b8-4548-8dfe-86310b7b2e43",
   "metadata": {},
   "source": [
    "## 分類タスクの実行"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca8938b6-01ef-44fa-9039-a43de48189a8",
   "metadata": {},
   "source": [
    "### ステップ10\n",
    "訓練したモデルにテスト用データを与えて評価する\n",
    "* ここではファイルから読み込んだモデル（restored_model）をcnn_trainer経由で使用\n",
    "* 返値は評価結果（予測精度と損失の値）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43325b6e-1bbe-49c4-a25a-c953f04808f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataloader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=len(test_dataset) # 全データを一括で評価する\n",
    ")\n",
    "print(cnn_trainer_restored.test(restored_model, dataloaders=test_dataloader))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd3d63be-ca05-4aaa-985e-48c4832d2ef4",
   "metadata": {},
   "source": [
    "### ステップ11\n",
    "訓練したモデルにテスト用データを与えて分類を実行する\n",
    "* ここではファイルから読み込んだモデル（restored_model）をcnn_trainer_restored経由で使用\n",
    "* 返値は予測結果（ニューラルネットワークの出力ベクトル）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c146657-7041-4944-9f38-0d8ba585c010",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images, test_labels = next(iter(test_dataloader)) # 画像とラベルをTensorで取得\n",
    "probs = cnn_trainer_restored.predict(dataloaders=DataLoader(test_images, batch_size=len(test_dataset)))\n",
    "predictions = torch.cat(probs, dim=0) # リストprobの要素を結合して1つのTensorにする\n",
    "predictions = nn.functional.softmax(predictions, dim=1) # 各クラスの予測値の合計が1になるようにする（確率に変換）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1635a28-fba8-43b4-b4d7-8b2d0e51db4f",
   "metadata": {},
   "source": [
    "### ステップ12\n",
    "予測した結果をグラフに表示する関数を定義\n",
    "* 画像\n",
    "* 正解ラベル\n",
    "* 分類結果（各数字に分類される確率）\n",
    "の引数を与え，それぞれを並べて表示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8114856c-4aac-4b02-aae6-90fcd344b112",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_prediction_result(image, correct, result):\n",
    "    figure = plt.figure(figsize = (6, 3))\n",
    "    subplot = plt.subplot(1, 2, 1)\n",
    "    plt.imshow(image, cmap = plt.cm.binary)\n",
    "    plt.title(\"correct label = {}\".format(correct))\n",
    "    plt.axis(\"off\")\n",
    "    subplot = plt.subplot(1, 2, 2)\n",
    "    plt.bar(range(len(result)), result)\n",
    "    plt.xticks(range(len(result)), range(len(result)))\n",
    "    plt.ylim(0, 1)\n",
    "    plt.title(\"probabilites\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3451b3a1-d29f-45ce-8918-d3b8235ccdd9",
   "metadata": {},
   "source": [
    "### ステップ13\n",
    "予測結果が正しい例，異なっている例を num_examples だけ取り出して表示\n",
    "* どのような間違いが起こっているかを確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2489e4-f923-49c7-bccb-faa60dee06ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_examples = 5\n",
    "count = 0\n",
    "print(\"\")\n",
    "print(\"正しく分類された画像の例\") \n",
    "for i in range(len(predictions)):\n",
    "    if (np.argmax(predictions[i]) == test_labels[i]):\n",
    "        show_prediction_result(test_images[i].squeeze(), test_labels[i], predictions[i])\n",
    "        count += 1\n",
    "        if (count > num_examples):\n",
    "            break\n",
    "print(\"\")\n",
    "print(\"誤って分類された画像の例\")\n",
    "count = 0\n",
    "for i in range(len(predictions)):\n",
    "    if (np.argmax(predictions[i]) != test_labels[i]):\n",
    "        show_prediction_result(test_images[i].squeeze(), test_labels[i], predictions[i])\n",
    "        count += 1\n",
    "        if (count > num_examples):\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce5f18e-099c-4f11-a4c8-86bdb8323692",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
