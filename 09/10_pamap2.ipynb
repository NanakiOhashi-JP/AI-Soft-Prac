{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PAMAP2 Physical Activity Monitoring データの分析サンプル（後半・途中までは前回説明済み）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 準備作業（データ読み込み等）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "必要なライブラリのインポート"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "すべてのファイルからデータを読み込み，データフレームを作成する．ここでは，ファイルをリスト化し，カラムの各列のヘッダを作成する．\n",
    "##### ・ファイル名のリスト作成：各被験者のデータファイルを読み込むためにファイル名をリスト化\n",
    "##### ・活動ラベルの辞書作成：各活動の番号（ラベル）と名前（例：1=lying，2=sitting）を辞書にマッピング\n",
    "##### ・IMUカテゴリのリスト作成：各センサー（手首，胸，足首）のデータ列名を別々にリスト化\n",
    "##### ・カラムコレクションの統合：タイムスタンプ，活動ラベル，心拍数，各IMUカテゴリのデータ列名をすべて結合し，データフレームのカラム名を作成\n",
    "最後に，作成したヘッダに対して列数を表示する．各データファイルは54列あるので，それと等しくなっていればよい．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "list_of_files = ['PAMAP2_Dataset/Protocol/subject101.dat',\n",
    "                 'PAMAP2_Dataset/Protocol/subject102.dat',\n",
    "                 'PAMAP2_Dataset/Protocol/subject103.dat',\n",
    "                 'PAMAP2_Dataset/Protocol/subject104.dat',\n",
    "                 'PAMAP2_Dataset/Protocol/subject105.dat',\n",
    "                 'PAMAP2_Dataset/Protocol/subject106.dat',\n",
    "                 'PAMAP2_Dataset/Protocol/subject107.dat',\n",
    "                 'PAMAP2_Dataset/Protocol/subject108.dat',\n",
    "                 'PAMAP2_Dataset/Protocol/subject109.dat' ]\n",
    "\n",
    "subjectID = [1,2,3,4,5,6,7,8,9]\n",
    "\n",
    "activityIDdict = {0: 'transient',\n",
    "              1: 'lying',\n",
    "              2: 'sitting',\n",
    "              3: 'standing',\n",
    "              4: 'walking',\n",
    "              5: 'running',\n",
    "              6: 'cycling',\n",
    "              7: 'Nordic_walking',\n",
    "              9: 'watching_TV',\n",
    "              10: 'computer_work',\n",
    "              11: 'car driving',\n",
    "              12: 'ascending_stairs',\n",
    "              13: 'descending_stairs',\n",
    "              16: 'vacuum_cleaning',\n",
    "              17: 'ironing',\n",
    "              18: 'folding_laundry',\n",
    "              19: 'house_cleaning',\n",
    "              20: 'playing_soccer',\n",
    "              24: 'rope_jumping' }\n",
    "\n",
    "colNames = [\"timestamp\", \"activityID\",\"heartrate\"]\n",
    "\n",
    "IMUhand = ['handTemperature', \n",
    "           'handAcc16_1', 'handAcc16_2', 'handAcc16_3', \n",
    "           'handAcc6_1', 'handAcc6_2', 'handAcc6_3', \n",
    "           'handGyro1', 'handGyro2', 'handGyro3', \n",
    "           'handMagne1', 'handMagne2', 'handMagne3',\n",
    "           'handOrientation1', 'handOrientation2', 'handOrientation3', 'handOrientation4']\n",
    "\n",
    "IMUchest = ['chestTemperature', \n",
    "           'chestAcc16_1', 'chestAcc16_2', 'chestAcc16_3', \n",
    "           'chestAcc6_1', 'chestAcc6_2', 'chestAcc6_3', \n",
    "           'chestGyro1', 'chestGyro2', 'chestGyro3', \n",
    "           'chestMagne1', 'chestMagne2', 'chestMagne3',\n",
    "           'chestOrientation1', 'chestOrientation2', 'chestOrientation3', 'chestOrientation4']\n",
    "\n",
    "IMUankle = ['ankleTemperature', \n",
    "           'ankleAcc16_1', 'ankleAcc16_2', 'ankleAcc16_3', \n",
    "           'ankleAcc6_1', 'ankleAcc6_2', 'ankleAcc6_3', \n",
    "           'ankleGyro1', 'ankleGyro2', 'ankleGyro3', \n",
    "           'ankleMagne1', 'ankleMagne2', 'ankleMagne3',\n",
    "           'ankleOrientation1', 'ankleOrientation2', 'ankleOrientation3', 'ankleOrientation4']\n",
    "\n",
    "columns = colNames + IMUhand + IMUchest + IMUankle  #all columns in one list\n",
    "\n",
    "len(columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "データファイルを読み込む．データファイルは，スペースで区切られているのでスペースごとに1行を読み込み，レコードを生成してデータフレームに保存している（保存の際に，ファイル名の数字部分から被験者ID：subject_id を生成して，データに付加している）．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataCollection = pd.DataFrame()\n",
    "for file in list_of_files:\n",
    "    procData = pd.read_table(file, header=None, sep=r'\\s+')\n",
    "    procData.columns = columns\n",
    "    procData['subject_id'] = int(file[-5])\n",
    "    dataCollection = pd.concat([dataCollection, procData], ignore_index=True)\n",
    "\n",
    "dataCollection.reset_index(drop=True, inplace=True)\n",
    "dataCollection.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上記のデータには，クリーニングしなければならないデータがある．たとえば，activityID が 0 のデータは，被験者が特定の活動をしていないことを示している．またいくつかの欠損値がある．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### データクレンジング"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PerformedActivitiesSummary.pdf** ファイルを参照すると，すべての被験者がすべての活動を行ったわけではない．したがって，欠損値が存在する．また，activityID が0 のデータは特定の活動をしていない．この値が変化していても，分析対象からは外す．次の順で実施するクレンジング用の関数を作成．\n",
    "##### ・未使用のオリエンテーションデータレコード（3か所につき4種類ずつ）を削除\n",
    "##### ・activityID が 0 のデータを削除\n",
    "##### ・データ全体を数値化．数値化できないものは NaN に変換\n",
    "##### ・NaN データ（欠損データ）を，前後のデータから補間（上端の欠損値はそのままになる）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataCleaning(dataCollection):\n",
    "        dataCollection = dataCollection.drop(['handOrientation1', 'handOrientation2', 'handOrientation3', 'handOrientation4',\n",
    "                                             'chestOrientation1', 'chestOrientation2', 'chestOrientation3', 'chestOrientation4',\n",
    "                                             'ankleOrientation1', 'ankleOrientation2', 'ankleOrientation3', 'ankleOrientation4'],\n",
    "                                             axis = 1)  # removal of orientation columns as they are not needed\n",
    "        dataCollection = dataCollection.drop(dataCollection[dataCollection.activityID == 0].index) #removal of any row of activity 0 as it is transient activity which it is not used\n",
    "        dataCollection = dataCollection.apply(pd.to_numeric, errors = 'coerce') #removal of non numeric data in cells\n",
    "        dataCollection = dataCollection.interpolate() #removal of any remaining NaN value cells by constructing new data points in known set of data points\n",
    "        \n",
    "        return dataCollection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataCol = dataCleaning(dataCollection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataCol.reset_index(drop = True, inplace = True)\n",
    "dataCol.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataCol.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NaN のまま残っているのは，heartrate の 4 データであることが分かる（1 人目のデータの最初の4データ）．ここでは，5 行目以降のデータから同様に 100 を設定することが妥当そうなので，単純に 100 を代入する．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,4):\n",
    "    dataCol.loc[i, \"heartrate\"]=100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "これにより，欠損値はなくなる．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataCol.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 探索的データ分析"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 教師データとテストデータに分割"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "データ分割の前に，データ数の偏りをなるべくなくす必要がある．各クラスの重みがアンバランスであれば，サンプリングを行う必要がある．クラスの割合が，80% 対 20% を超える場合は，明らかに不均衡．ここではそのような状態でないかをまず確認する． "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "activityID ごとのデータ件数を可視化すると，次のようになる．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataCol['activityID'].value_counts().plot(kind = \"bar\",figsize = (12,6))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "これより，全体の80% を超えるクラスはなさそうなので，そのまま利用する．教師データとテストデータに分割．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = dataCol.sample(frac=0.8, random_state=1)\n",
    "test_df = dataCol.drop(train_df.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "データが用意できていそうなことを，確認する．教師データ，テストデータそれぞれを表示．分布が大きく変わっていなければよい．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.float_format = '{:.2f}'.format\n",
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "心拍数は，被験者の状態を追跡するための重要な要素なので，どれくらいの分布をしているかを箱ひげ図で可視化．そのまえに，箱ひげ図や後で出てくるヒートマップを描画するライブラリをインストール．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(4,4))\n",
    "plt.title(\"Heart Rate \")\n",
    "ax = sns.boxplot(y=train_df[\"heartrate\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "心拍数の箱ひげ図より，心拍数が180 を超える外れ値が存在していることがわかる．これらは非常に高い心拍数で，非常に激しいアクティビティや異常値である可能性がある．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最も負担の大きいアクティビティを見つけるために，各アクティビティごとの平均心拍数を示す棒グラフを描画．どのアクティビティが最も心拍数が高いか，つまり最も負担が大きいアクティビティを見つけることに利用できる．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hr_act = train_df['heartrate'].groupby(train_df['activityID']).mean()\n",
    "df_hr_act.index = df_hr_act.index.map(activityIDdict)\n",
    "df_hr_act.plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "この棒グラフからは，ランニングと縄跳びが心拍数への負荷が高そうなことが分かる．それらが他の活動に対して有意差があるかどうかは，後で確認する．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "次にデータの異常や相関関係を調べるために，相関係数を求めてからヒートマップを作成する．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pandas.plotting import scatter_matrix\n",
    "df_corr = train_df.corr()\n",
    "df_corr = df_corr.drop(['activityID'], axis = 1)\n",
    "\n",
    "f, ax = plt.subplots(figsize=(15, 10))\n",
    "sns.heatmap(df_corr, mask=np.zeros_like(df_corr, dtype=np.bool), cmap = \"BrBG\",ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "このヒートマップからは次のことが分かる（次は一例）：\n",
    "##### ・ジャイロスコープのデータはほかのどのデータともあまり関係していないように見え，この分析では不要．\n",
    "##### ・心拍数と各部位の加速度計には相関がある．足首の加速度計とは正の相関，それ以外の部分とは負の相関．\n",
    "##### ・心拍数と各部位の磁力計には相関がある．足首の磁力計とは負の相関，それ以外の部分とは正の相関．\n",
    "##### → 上半身の身体活動は心拍数を上げて，下半身は下げる？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 仮説の検定"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最も負荷の高い活動は，ランニングと縄跳び．それらが他の活動と差があるかどうかを検定する．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**帰無仮説: **\n",
    "- h0 : 負荷の高い活動の心拍数の平均値は，すべての活動に対して有意な差がない\n",
    "\n",
    "**対立仮説: **\n",
    "\n",
    "- h1 : 負荷の高い活動の心拍数の平均値は，すべての活動に対して大きく異なる"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "まず，ランニング(5) と縄跳び(24) のデータを取り出す．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "running_data = train_df.loc[(train_df[\"activityID\"] == 5)]\n",
    "ropejumping_data = train_df.loc[(train_df[\"activityID\"] == 24)]\n",
    "cumbersome_data = pd.concat([running_data,ropejumping_data])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "それ以外のデータを取り出す．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_data = train_df.loc[(train_df[\"activityID\"] != 5)]\n",
    "other_data = other_data.loc[(other_data[\"activityID\"] != 24)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "t検定を行い，p値を算出する．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats\n",
    "stat, pValue = scipy.stats.ttest_ind(cumbersome_data['heartrate'], other_data['heartrate'], equal_var=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if pValue > 0.1:\n",
    "    print(\"p値は\", pValue, \"で，対立仮説 h1 が棄却されました．負荷の高い活動の心拍数の平均値は，すべての活動に対して有意な差がありません．\")\n",
    "else:\n",
    "    print(\"p値は\", pValue, \"で，帰無仮説 h0 が棄却されました．負荷の高い活動の心拍数の平均値は，すべての活動に対して大きく異なります．\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
